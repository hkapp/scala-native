\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[left=3cm,right=3cm,top=3cm,bottom=3cm]{geometry}

\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}

\usepackage{listings}
\usepackage{color}

\lstset{
	language=Scala,
	keywordstyle=\color{blue},
	frame = single
}

\author{Hugo Kapp 227942}
\title{Semester project report}

\newcommand{\scala}[1]{\textsf{#1}}
\newcommand{\nir}[1]{\texttt{#1}}

\begin{document}

\maketitle

\section{Introduction}

We explain in this report all that was done during this semester project : the goals, the ideas and results achieved. We give in this section insights about why this project is important, as well as the ground we start with. We then give the details of each optimization that is implemented, and pointers to their correctness.

\subsection{Motivation}

In recent compilers, compilation speed is an issue. This is particularly important in Scala compilers, because the richness of the language is hard to resolved automatically. The process is therefore slower than for other languages. For ScalaNative, this problem is worsened by the long compilation time of LLVM, which is relatively slow when applied to big files. Because there is no dynamic linking in ScalaNative, all symbols and definitions that can be reached during the execution of the program are statically linked during compilation. This leads to a very big program that needs to go through the whole compilation pipeline, even for very small input programs.

All of this makes the ScalaNative compiler very slow, and produces huge executables.

\subsection{Goal}

The goal of this project is therefore to reduce the amount of code worked with, through various optimizations. We could let the LLVM compiler take care of all of this, as it has a very efficient optimization pipeline. The idea here is to take advantage of the domain-specific knowledge we have, before it is lost due to primitives lowering to LLVM. On top of that, having less code to perform the passes on should speed up the compilation.

The only goal here is code reduction, and not execution speed. Any reduction in the final size of the executable, as well as compilation or execution speed-up, in totally incidental, but will still be noted.

\subsection{The ScalaNative compiler}

Before we start explaining the various optimizations implemented and their impact, we first need to talk a little bit about the compiler organization and specific. Only what is necessary is explained here, and kept abstract. For more details on the compiler, please refer to the documentation in \cite{nativedoc}.

\subsection*{Compiler organization}

The compiler is organized as a classic pipeline consisting of a sequence of \scala{Pass}.  For this project, we only add passes to the compilation pipeline, which will alter the current form of the code.

\subsubsection*{Native Intermediate Representation}

Scala Native uses its own intermediate representation (IR), called \textit{Native Intermediate Representation} and abbreviated NIR.

It is in SSA form, which stands for \textit{Static Single Assignment}. This means that variables have only one static definition in the program, which can be performed multiple times during execution. Different values can then be merged to define a new variable, using the concept of $\phi$-functions that can be found in the litterature (see \cite{ssabook}). In NIR, classic $\phi$-functions are replaced by arguments passed to each basic block.

The instruction set of NIR is composed of a subset of LLVM operations, with the same semantics, plus some high-level constructs coming from Scala. The latter are lowered during the compilation process to be expressed in terms of LLVM instructions.

Further details about NIR can be found in \cite{nirdoc}.

\section{Global Value Numbering}

The first optimization implementend is called Global Value Numbering, and sometimes abbreviated GVN.

\subsection{Idea}

The idea is taken directly from \cite{ssabook}, which also provides a proof of correctness. The general idea is to reuse the result of computations that were already made in the past, which makes GVN a redundancy elimination optimzation. To be able to do that, two conditions need to be met :

\begin{enumerate}
\item The two computations yield the same result in all cases, and there is no side-effect
\item In all possible paths of the control flow, the result we want to reuse has been computed before the location we want to reuse it at
\end{enumerate}

The first condition is very simple to understand, but the second might seem more complex. It can be explained using the example in Figure \ref{fig:gvn}. In \ref{fig:gvn1}, the computation \scala{a + 1} is not necessarily done when we reach the definition of \scala{c}. In \ref{fig:gvn2}, the result has already been computed when we reach the definition for \scala{b}, so we can avoid the re-computation of \scala{a + 1}.

\begin{figure}[h]
	\begin{subfigure}{0.5\textwidth}
		\begin{lstlisting}
if (...) {
  val b = a + 1
  ...
}
val c = a + 1
		\end{lstlisting}
		\caption{Unreduceable code}
		\label{fig:gvn1}
	\end{subfigure}
	\quad
	\begin{subfigure}{0.5\textwidth}
		\begin{lstlisting}
val c = a + 1
if (...) {
  val b = a + 1
  // val b = c
  ...
}
		\end{lstlisting}
		\caption{Reduceable code}
		\label{fig:gvn2}
	\end{subfigure}
	\caption{GVN examples}
	\label{fig:gvn}
\end{figure}

\subsection{Value Numbering}

Following its name, GVN uses value numbering to achieve the first condition. This is opposed to syntactic redundancy, where we consider that two expressions yield the same result only if they are written the same way (modulo the commutativity of operations).

In value numbering, each variable in the program has a hash value associated to it. We call the function that gives these hashes $h$. The hash value for variable $v$ is then given by $h(v)$. This value is computed using the defining operation for $v$, and the hash value for each of its operand. Note that this only works on programs that are in SSA form, like the NIR, because we need a single definition for each variable.

For example, say we have \nir{\%b = \%a + 1}. Then $h(\nir{\%b}) = h(\nir{\%a + 1}) = agg(\nir{+}, h(\nir{\%a}), h(\nir{1}))$. The aggregation function used ($agg$) is any hashing function.

Bootstrapping is done by giving each input variable a value that depend on its name. Constants are give a hash that depends on their value.

\subsection{Dominator tree}

To check for the second condition discussed earlier, we use the concept of dominator tree, also discussed in the SSA book \cite{ssabook}. From this very book, we get the following definition for domination :
\newline
A basic block $n_1$ \textit{dominates} basic block $n_2$ if every path in the control flow graph from the entry point to $n_2$ includes $n_1$. By convention, every basic block dominates itself.

In other words, $n_2$ is dominated by $n_1$ if we have to go through $n_1$ before going to $n_2$. Thus, if $v_1$ is defined in block $n_1$ and $v_2$ is defined in block $n_2$, and $n_1$ dominates $n_2$, then we know that the value of $v_1$ has been computed when we reach the definition of $v_2$. Note that this only holds if $n_1 \neq n_2$, but if it is the case, then it is trivial to check that $v_1$ is indeed defined before $v_2$.

We use this to build the dominator tree, which gives, for each block in the CFG, the set of blocks that dominate it. This allows us to easily check if the value of a variable $v$ can be used at a given point $p$ in the program, by verifying that $p$'s basic block is dominated by the block in which $v$ is defined.

\subsection{Algorithm}

Using both parts, we can then easily check which variables always have the same value, and reduce the ones computed later. The algorithm is as follows : \newline
For each instruction:
\begin{enumerate}
\item Compute the value for $v$, $h(v)$, using the values for its operands
\item For each variable $w$ that has the same value :
	\begin{enumerate}
	\item Check if the definitions for $v$ and $w$ match
	\item Check if the value of $w$ can be reused at $v$
	\item If both conditions are verified, then replace $v$ by $w$
	\end{enumerate}
\end{enumerate}

\subsection{Implementation}

\section{Control-flow optimizations}


\section{InstCombine}

% need a note on passes placement

\section{Results}


\begin{thebibliography}{9}

   \bibitem{nativedoc} Scala Native documentation \newline \url{http://scala-native.readthedocs.io}

	\bibitem{nirdoc} NIR documentation \newline \url{http://scala-native.readthedocs.io/en/latest/contrib/nir.html}
	
	\bibitem{ssabook} SSA book

\end{thebibliography}


\end{document}